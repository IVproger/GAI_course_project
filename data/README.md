# 💾 Data Directory (`data/`)

This directory serves as the central location for all datasets and data-related artifacts used and generated by the project.

## Structure

-   **`paper_dataset/`**: Contains the raw input datasets.
    -   Example: `dog/` might contain the specific subject images (e.g., photos of the 'xon' dog) used for DreamBooth fine-tuning.
-   **`prior_imgs/`**: Contains data generated for prior preservation loss.
    -   Example: `dog_updated/` might hold the pre-generated latents (`.pt`), embeddings (`.pt`), and attention masks (`.pt`) corresponding to the class prompt (e.g., "a photo of a dog").

## Purpose

-   **Input Data:** Provides the source images required for training the model on specific subjects.
-   **Generated Data:** Stores intermediate or auxiliary data needed for specific training techniques like prior preservation.

## Usage

-   Paths to subdirectories within `data/` (e.g., `data/paper_dataset/dog`, `data/prior_imgs/dog_updated`) are typically specified in configuration files located in the `configs/` directory.
-   The `scripts/generate_priors.py` script saves its output into the `prior_imgs/` subdirectory.
-   The `scripts/train.py` script reads both subject images and prior preservation data from this directory based on the provided configuration.

## Note on Version Control

Generated data (like the contents of `prior_imgs/`) can be large. Consider:
-   Adding `data/prior_imgs/` to your `.gitignore` file if the data is easily reproducible by running `scripts/generate_priors.py`.
-   Using [Git LFS](https://git-lfs.github.com/) (Large File Storage) if you need to track large data files directly in Git.
-   Storing large datasets in dedicated external storage (like S3, GCS, network drives) and referencing their paths in configurations.

Choose the strategy that best suits your project's needs and reproducibility requirements.


## 📥 Accessing Inference Data  

The inference data used in the **DreamBooth** paper is available in the official repository:  

🔗 **[DreamBooth Dataset – GitHub](https://github.com/google/dreambooth)**  

### 📌 Instructions  

Before downloading, ensure you are inside the `data/` directory of the project. Follow these steps:  

### **1️⃣ Navigate to the Data Folder**  
```bash
cd data/
```

### **2️⃣ Clone the Dataset Repository**  
```bash
git clone https://github.com/google/dreambooth.git
```

### **3️⃣ Verify the Download**  
Ensure the dataset is correctly placed in the `data/` directory by listing the contents:  
```bash
ls dreambooth/
```

### **4️⃣ Proceed with Model Training or Inference**  
Now, you can use this dataset for fine-tuning and inference within your project.  

---

💡 *For more details on the dataset, visit the [official DreamBooth GitHub repository](https://github.com/google/dreambooth).* 🚀


---


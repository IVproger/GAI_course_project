{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDPMScheduler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "scheduler = DDPMScheduler.from_config(model_id, subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze UNet and text encoder\n",
    "pipe.unet.requires_grad_(True)\n",
    "pipe.text_encoder.requires_grad_(True)\n",
    "optimizer = AdamW(\n",
    "    list(pipe.unet.parameters()) + list(pipe.text_encoder.parameters()),\n",
    "    lr=5e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy datasets (replace with actual data loading)\n",
    "subject_latents = torch.randn(3, 4, 64, 64).to(\"cuda\")  # Example subject latents\n",
    "subject_prompts = [\"a sks dog\"] * 3\n",
    "prior_latents = torch.randn(100, 4, 64, 64).to(\"cuda\")  # Pre-generated prior latents\n",
    "prior_prompts = [\"a dog\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "lambda_prior = 1.0\n",
    "batch_size = 1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Subject loss\n",
    "    for i in range(0, len(subject_latents), batch_size):\n",
    "        batch_latents = subject_latents[i:i+batch_size]\n",
    "        batch_prompts = subject_prompts[i:i+batch_size]\n",
    "        \n",
    "        # Noise and timesteps\n",
    "        noise = torch.randn_like(batch_latents)\n",
    "        timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (batch_size,)).to(\"cuda\")\n",
    "        \n",
    "        # Add noise\n",
    "        noisy_latents = scheduler.add_noise(batch_latents, noise, timesteps)\n",
    "        \n",
    "        # Encode text\n",
    "        text_input = pipe.tokenizer(\n",
    "            batch_prompts, padding=\"max_length\",\n",
    "            max_length=pipe.tokenizer.model_max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "        text_embeddings = pipe.text_encoder(text_input.input_ids)[0]\n",
    "        \n",
    "        # Predict noise\n",
    "        noise_pred = pipe.unet(noisy_latents, timesteps, text_embeddings).sample\n",
    "        subject_loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "        \n",
    "    # Prior loss\n",
    "    for i in range(0, len(prior_latents), batch_size):\n",
    "        batch_prior = prior_latents[i:i+batch_size]\n",
    "        batch_prior_prompts = prior_prompts[i:i+batch_size]\n",
    "        \n",
    "        noise_prior = torch.randn_like(batch_prior)\n",
    "        timesteps_prior = torch.randint(0, scheduler.config.num_train_timesteps, (batch_size,)).to(\"cuda\")\n",
    "        \n",
    "        noisy_prior = scheduler.add_noise(batch_prior, noise_prior, timesteps_prior)\n",
    "        \n",
    "        prior_text_input = pipe.tokenizer(\n",
    "            batch_prior_prompts, padding=\"max_length\",\n",
    "            max_length=pipe.tokenizer.model_max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "        prior_embeddings = pipe.text_encoder(prior_text_input.input_ids)[0]\n",
    "        \n",
    "        noise_pred_prior = pipe.unet(noisy_prior, timesteps_prior, prior_embeddings).sample\n",
    "        prior_loss = torch.nn.functional.mse_loss(noise_pred_prior, noise_prior)\n",
    "    \n",
    "    # Total loss\n",
    "    loss = subject_loss + lambda_prior * prior_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
